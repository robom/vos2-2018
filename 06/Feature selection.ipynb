{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Obsah\n",
    "\n",
    "> ## Filter\n",
    "\n",
    "> ## Wrapper\n",
    "\n",
    "> ## Embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preco by som mal vyberat len niektore atributy?\n",
    "\n",
    "* redundancia - skryte zavyslosti medzi nimi \n",
    "* irelevancia - nemusia mat ziadny vplyv na predikovanu hodnotu\n",
    "* pretrenovanie - model sa da natrenovat aj na nahodnych datach a na trenovacej sade bude fungovat. Na testovacej ale bude fungovat uplne strasne\n",
    "* prekliatie dimenzionality - pri velkom pocte atributov potrebujem vela dat na to aby som dostatocne pokryl priestor moznych hodnot\n",
    "* produktivita / rychlost - moja ako analytika a aj mojich modelov (trenovanie aj predikcia)\n",
    "* zrozumitelnost - lahsie sa vysvetluje model, ktory ma menej atributov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 9, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Filter\n",
    "\n",
    "Vyber atributov bez ohladu na model, ktory sa chystame trenovat.\n",
    "\n",
    "* rychle\n",
    "* nezavisle na modeli (to je dobre aj zle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Najjednoduchsie je vyhodit atributy, ktore maju vsade rovnake hodnoty\n",
    "\n",
    "pozor, nie malu varianciu. Hlavne pri nevyvazenych triedach mozu byt prave taketo atributy velmi uzitocne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 3],\n",
       "       [0, 1, 4, 3],\n",
       "       [0, 1, 1, 3]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 4],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=0.0)\n",
    "selector.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Potom mozeme vyberat atributy na zaklade zavislosti atributu a predikovanej hodnoty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Priklad: vyberieme K vlastnosti, s najvyssou zavislostou s predikovanou hodnotou. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 # daju sa pouzit ine metriky\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Daju sa pouzivat rozne metriky\n",
    "> Klasifikacia\n",
    "* chi2 - nezaporne cisla\n",
    "* mutual_info_classif - diskretne data\n",
    "* f_classif - ANOVA medzi predikovanou premennou a atributmi\n",
    "\n",
    "> Regresia\n",
    "* f_regression - F test medzi predikovanou hodnotou a atributmi\n",
    "* mutual_info_regression - Mutual information na realnych cislach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Da sa vyberat K najlepsich alebo nejaky percentil alebo nechat pocet atributov na statisticky test\n",
    "\n",
    "* SelectKBest \n",
    "* SelectPercentile\n",
    "\n",
    "* SelectFpr - false positive rate\n",
    "* SelectFdr - false discovery rate  \n",
    "* SelectFwe - family wise error\n",
    "\n",
    "* GenericUnivariateSelect - Vsetko dohromady a strategia sa da nastavit parametrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Vlastnosti filtrov\n",
    "\n",
    "* vacsinou rychle\n",
    "* nezavisle na modely (nepotrebujem opakovane trenovat model ale vybrane atributy nemusia byt najvhodnejsie pre kazdy model)\n",
    "* vacsinou sa pozeraju len na vlastnosti dvojic predikovana premenna - atribut, kombinacie viacerych atributov nezohladnuju\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Varovanie, PCA sa casto pouziva na redukciu dimenzionality ale nie na vyber atributov\n",
    "\n",
    "Je to casta chyba\n",
    "\n",
    "Nemohol som si odpustit tuto poznamku\n",
    "\n",
    "Preco je to tak sa mozeme porozpravat v diskusii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Zakladna myslienka\n",
    "\n",
    "haldame podmnozinu atributov, na ktorej bude model davat najlepsie vysledky\n",
    "\n",
    "Skusame rozne podmnoziny a vyberame tu najlepsiu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Problem\n",
    "\n",
    "Ak mame dataset s N atributmi, tak pocet roznych podmnozin je $2^N$\n",
    "\n",
    "To znamena, ze by sme museli nas model natrenovat $2^N$ krat.\n",
    "\n",
    "Chcelo by to najst proces, ktory minimalizuje pocet pokusov a zaroven maximalizuje uspesnost modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Greedy pristupy\n",
    "\n",
    "Najcastejsie sa pouzivaju greedy pristupy, ktore postupne zvacsuju sadu atributov (alebo zmensuju) tak, ze pridavaju (odoberaju) atribut tak aby sa co najviac zvysila uspesnost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Mlxtend\n",
    "\n",
    "* Sequential Forward Selection (SFS)\n",
    "> Postupne zvacsuje mnozinu atributov o ton, ktory najviac prispel k zlepseniu\n",
    "\n",
    "* Sequential Backward Selection (SBS)\n",
    "> Postupne zmensuje mnzoinu atributov o ten, ktory najmenej pomahal\n",
    "\n",
    "* Sequential Floating Forward Selection (SFFS)\n",
    "> SFS s pokusom o vyhodenie uz pridanych atributov ak sa ukaze ze velmi nepomahaju \n",
    "\n",
    "* Sequential Floating Backward Selection (SFBS)\n",
    "> SBS s pokusom o pridanie uz raz vyhodeneho atributu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "* RFE - Recursive feature elimination\n",
    "> Postupne vyhadzovanie atributov, ktore maju v modeli najnizsiu vahu (potrebujeme aby to model vedel povedat) \n",
    "\n",
    "* RFECV - RFE with cross-validation\n",
    "> RFE s cross validaciou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Priklad SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "knn = KNeighborsClassifier(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2018-10-23 21:34:26] Features: 1/3 -- score: 0.96[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2018-10-23 21:34:26] Features: 2/3 -- score: 0.9733333333333334[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2018-10-23 21:34:26] Features: 3/3 -- score: 0.9733333333333334"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(knn, k_features=3, forward=True,  floating=False, verbose=2, scoring='accuracy', cv=0)\n",
    "# pomocou tejto triedy vieme robit SFS, SFFS, SBS aj SFBS a dokonca aj pridat cross-validaciu\n",
    "\n",
    "sfs1 = sfs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'avg_score': 0.96, 'cv_scores': array([0.96]), 'feature_idx': (3,)},\n",
       " 2: {'avg_score': 0.9733333333333334,\n",
       "  'cv_scores': array([0.97333333]),\n",
       "  'feature_idx': (2, 3)},\n",
       " 3: {'avg_score': 0.9733333333333334,\n",
       "  'cv_scores': array([0.97333333]),\n",
       "  'feature_idx': (1, 2, 3)}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Viem si vytiahnut zoznam najlepsich vlastnosti a uspesnost modelu pri nich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Hlavna myslienka\n",
    "\n",
    "Skombinovat vyhody filtrov a wrapprov\n",
    "\n",
    "Model, ktory sa trenuje si bude priamo vyberat atributy, ktore su pre neho najlepsie\n",
    "\n",
    "* Linearne modely penalizovnae L1 (Lasso) alebo L1+L2 (Elastic Net) regularizaciou: SVM, Linearna regresia, Logisticka regresia ...\n",
    "* RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0800782 , 0.0481432 , 0.26086959, 0.610909  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Zaver\n",
    "\n",
    "Zvazte ktory sposob vyberu atributov sa hodi prave pre vas. Zalezi to hlavne od pouziteho algoritmu na vytvorenie modelu.\n",
    "\n",
    "* Ak pouzivate nejaky linearny model alebo les, tak je zbytocne robit filtre a este viac zbytocne robit wrappre.\n",
    "\n",
    "* Ak nemate cas na opakovane trenovanie modelu, tak filtre mozu byt dostatocny hotfix. Treba ale zvazit aku vlastnost atributov chcete pouzit na najdenie najdolezitejsich. \n",
    "\n",
    "* Ak mate cas spustit to trenovanie viac krat, tak asi najlepsia moznost je SFFS alebo SFECV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Zdroje\n",
    "\n",
    "* http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "* http://jotterbach.github.io/2016/03/24/Principal_Component_Analysis/\n",
    "* https://plot.ly/scikit-learn/plot-feature-selection/\n",
    "* https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/\n",
    "* http://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html?utm_content=buffer42ed6&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
